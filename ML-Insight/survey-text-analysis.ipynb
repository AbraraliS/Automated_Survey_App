{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116eafcc",
   "metadata": {},
   "source": [
    "# Survey Text Response Analysis\n",
    "\n",
    "This notebook processes open-ended survey text responses using NLP techniques, sentiment analysis, topic modeling, and keyword extraction. Visualizations and markdown explanations are provided for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8b718",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We will use pandas, numpy, nltk, sklearn, matplotlib, seaborn, wordcloud, VADER, and optionally HuggingFace, BERTopic, and KeyBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "497ba2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "except ImportError:\n",
    "    pipeline = None\n",
    "try:\n",
    "    from bertopic import BERTopic\n",
    "except ImportError:\n",
    "    BERTopic = None\n",
    "try:\n",
    "    from keybert import KeyBERT\n",
    "except ImportError:\n",
    "    KeyBERT = None\n",
    "try:\n",
    "    from rake_nltk import Rake\n",
    "except ImportError:\n",
    "    Rake = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef596441",
   "metadata": {},
   "source": [
    "## 2. Load Survey Responses from JSON\n",
    "We will load the survey responses from the JSON file (`survey-results.json`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f200581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "survey: {'survey_id': 'f5ae24e1-9985-450b-b36c-878ffa7f471d', 'topic': 'Student AI/ML session review', 'audience': 'College Student', 'created_at': '2025-08-30T16:56:55.019098+00:00', 'questions_count': 5, 'responses_count': 5} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the survey data from JSON file\n",
    "with open('survey-results-f5ae24e1-9985-450b-b36c-878ffa7f471d.json', 'r', encoding='utf-8') as f:\n",
    "    survey_data = json.load(f)\n",
    "\n",
    "# Preview the structure of the JSON data\n",
    "print('Type:', type(survey_data))\n",
    "if isinstance(survey_data, dict):\n",
    "    for k, v in survey_data.items():\n",
    "        print(f'{k}:', str(v)[:300], '\\n')\n",
    "        break\n",
    "elif isinstance(survey_data, list):\n",
    "    print('Sample record:', survey_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d9a44",
   "metadata": {},
   "source": [
    "## 3. Extract All Text-Based Answers\n",
    "We will extract all open-ended (text) responses from the survey data for NLP analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35e7bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1 text responses.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student AI/ML session review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       response\n",
       "0  Student AI/ML session review"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract all text-based answers from the survey data\n",
    "def extract_text_responses(survey_data):\n",
    "    # Flatten all text answers from all responses\n",
    "    text_responses = []\n",
    "    if isinstance(survey_data, dict):\n",
    "        records = list(survey_data.values())\n",
    "        if isinstance(records[0], list):\n",
    "            records = records[0]\n",
    "    elif isinstance(survey_data, list):\n",
    "        records = survey_data\n",
    "    else:\n",
    "        records = []\n",
    "    for resp in records:\n",
    "        if isinstance(resp, dict):\n",
    "            for k, v in resp.items():\n",
    "                if isinstance(v, str) and len(v.split()) > 2:  # Heuristic: longer text\n",
    "                    text_responses.append(v)\n",
    "    print(f'Extracted {len(text_responses)} text responses.')\n",
    "    return pd.DataFrame({'response': text_responses})\n",
    "\n",
    "text_df = extract_text_responses(survey_data)\n",
    "display(text_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96651a77",
   "metadata": {},
   "source": [
    "## 4. NLP Preprocessing\n",
    "We will preprocess the text responses: lowercasing, stopword removal, and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33e3c9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abrarali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Abrarali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Abrarali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student AI/ML session review</td>\n",
       "      <td>student session review</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       response               processed\n",
       "0  Student AI/ML session review  student session review"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download NLTK resources if not already present\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = [w.lower() for w in text.split()]\n",
    "    tokens = [w for w in tokens if w.isalpha() and w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "text_df['processed'] = text_df['response'].apply(preprocess)\n",
    "display(text_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda761f",
   "metadata": {},
   "source": [
    "## 5. Sentiment Analysis\n",
    "We will perform sentiment analysis using VADER (rule-based) and optionally a HuggingFace transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de336853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Abrarali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not load model distilbert/distilbert-base-uncased-finetuned-sst-2-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 779, in _error_catcher\n    yield\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 904, in _raw_read\n    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 887, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ~~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py\", line 479, in read\n    s = self.fp.read(amt)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py\", line 719, in readinto\n    return self._sock.recv_into(b)\n           ~~~~~~~~~~~~~~~~~~~~^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py\", line 1304, in recv_into\n    return self.read(nbytes, buffer)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py\", line 1138, in read\n    return self._sslobj.read(len, buffer)\n           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py\", line 820, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 1091, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 980, in read\n    data = self._raw_read(amt)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 903, in _raw_read\n    with self._error_catcher():\n         ~~~~~~~~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 784, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 494, in http_get\n    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py\", line 826, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...<2 lines>...\n        socket_options=self.socket_options,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py\", line 977, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...<10 lines>...\n        **response_kw,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n    ~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n    ~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 753, in connect\n    self.sock = sock = self._new_conn()\n                       ~~~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n        method=request.method,\n    ...<9 lines>...\n        chunked=chunked,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1137, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 312, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 557, in cached_files\n    raise e\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 470, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1008, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1161, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1725, in _download_to_tmp_and_move\n    http_get(\n    ~~~~~~~~^\n        url_to_download,\n        ^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        expected_size=expected_size,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 511, in http_get\n    return http_get(\n        url=url,\n    ...<6 lines>...\n        _tqdm_bar=_tqdm_bar,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 420, in http_get\n    r = _request_wrapper(\n        method=\"GET\", url=url, stream=True, proxies=proxies, headers=headers, timeout=constants.HF_HUB_DOWNLOAD_TIMEOUT\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 309, in _request_wrapper\n    response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 310, in http_backoff\n    response = session.request(method=method, url=url, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 09e99534-f013-4b02-a65d-9f1e16e03ff3)')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 737, in getattribute_from_module\n    return getattribute_from_module(transformers_module, attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 741, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 597, in from_pretrained\n    model_class = _get_model_class(config, cls._model_mapping)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 394, in _get_model_class\n    supported_models = model_mapping[type(config)]\n                       ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 803, in __getitem__\n    return self._load_attr_from_module(model_type, model_name)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 817, in _load_attr_from_module\n    return getattribute_from_module(self._modules[module_name], attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 739, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} neither in {module} nor in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification neither in <module 'transformers.models.distilbert' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\models\\\\distilbert\\\\__init__.py'> nor in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 737, in getattribute_from_module\n    return getattribute_from_module(transformers_module, attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 741, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 597, in from_pretrained\n    model_class = _get_model_class(config, cls._model_mapping)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 394, in _get_model_class\n    supported_models = model_mapping[type(config)]\n                       ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 803, in __getitem__\n    return self._load_attr_from_module(model_type, model_name)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 817, in _load_attr_from_module\n    return getattribute_from_module(self._modules[module_name], attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 739, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} neither in {module} nor in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification neither in <module 'transformers.models.distilbert' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\models\\\\distilbert\\\\__init__.py'> nor in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nwhile loading with DistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Optionally, use HuggingFace transformer model for sentiment\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pipeline:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     hf_sentiment = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment-analysis\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     text_df[\u001b[33m'\u001b[39m\u001b[33mhf_sentiment\u001b[39m\u001b[33m'\u001b[39m] = text_df[\u001b[33m'\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: hf_sentiment(x)[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1030\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1029\u001b[39m     model_classes = {\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m: targeted_task[\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m]}\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m     framework, model = \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m        \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madapter_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1040\u001b[39m model_config = model.config\n\u001b[32m   1041\u001b[39m hub_kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = model.config._commit_hash\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py:332\u001b[39m, in \u001b[36minfer_framework_load_model\u001b[39m\u001b[34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[39m\n\u001b[32m    330\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m class_name, trace \u001b[38;5;129;01min\u001b[39;00m all_traceback.items():\n\u001b[32m    331\u001b[39m             error += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwhile loading with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, an error is thrown:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtrace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    333\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not load model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with any of the following classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_tuple\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. See the original errors:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m         )\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    337\u001b[39m     framework = infer_framework(model.\u001b[34m__class__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Could not load model distilbert/distilbert-base-uncased-finetuned-sst-2-english with any of the following classes: (<class 'transformers.models.auto.modeling_auto.AutoModelForSequenceClassification'>, <class 'transformers.models.auto.modeling_tf_auto.TFAutoModelForSequenceClassification'>, <class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>). See the original errors:\n\nwhile loading with AutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 779, in _error_catcher\n    yield\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 904, in _raw_read\n    data = self._fp_read(amt, read1=read1) if not fp_closed else b\"\"\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 887, in _fp_read\n    return self._fp.read(amt) if amt is not None else self._fp.read()\n           ~~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py\", line 479, in read\n    s = self.fp.read(amt)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py\", line 719, in readinto\n    return self._sock.recv_into(b)\n           ~~~~~~~~~~~~~~~~~~~~^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py\", line 1304, in recv_into\n    return self.read(nbytes, buffer)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py\", line 1138, in read\n    return self._sslobj.read(len, buffer)\n           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^\nTimeoutError: The read operation timed out\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py\", line 820, in generate\n    yield from self.raw.stream(chunk_size, decode_content=True)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 1091, in stream\n    data = self.read(amt=amt, decode_content=decode_content)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 980, in read\n    data = self._raw_read(amt)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 903, in _raw_read\n    with self._error_catcher():\n         ~~~~~~~~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\response.py\", line 784, in _error_catcher\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\") from e  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 494, in http_get\n    for chunk in r.iter_content(chunk_size=constants.DOWNLOAD_CHUNK_SIZE):\n                 ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\models.py\", line 826, in generate\n    raise ConnectionError(e)\nrequests.exceptions.ConnectionError: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...<2 lines>...\n        socket_options=self.socket_options,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py\", line 977, in getaddrinfo\n    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nsocket.gaierror: [Errno 11001] getaddrinfo failed\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...<10 lines>...\n        **response_kw,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 488, in _make_request\n    raise new_e\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 464, in _make_request\n    self._validate_conn(conn)\n    ~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1093, in _validate_conn\n    conn.connect()\n    ~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 753, in connect\n    self.sock = sock = self._new_conn()\n                       ~~~~~~~~~~~~~~^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connection.py\", line 205, in _new_conn\n    raise NameResolutionError(self.host, self, e) from e\nurllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n    resp = conn.urlopen(\n        method=request.method,\n    ...<9 lines>...\n        chunked=chunked,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 519, in increment\n    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nurllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve 'huggingface.co' ([Errno 11001] getaddrinfo failed)\"))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1137, in _get_resolved_checkpoint_files\n    resolved_archive_file = cached_file(pretrained_model_name_or_path, filename, **cached_file_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 312, in cached_file\n    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 557, in cached_files\n    raise e\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\utils\\hub.py\", line 470, in cached_files\n    hf_hub_download(\n    ~~~~~~~~~~~~~~~^\n        path_or_repo_id,\n        ^^^^^^^^^^^^^^^^\n    ...<10 lines>...\n        local_files_only=local_files_only,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 114, in _inner_fn\n    return fn(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1008, in hf_hub_download\n    return _hf_hub_download_to_cache_dir(\n        # Destination\n    ...<14 lines>...\n        force_download=force_download,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1161, in _hf_hub_download_to_cache_dir\n    _download_to_tmp_and_move(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n        incomplete_path=Path(blob_path + \".incomplete\"),\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<8 lines>...\n        xet_file_data=xet_file_data,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 1725, in _download_to_tmp_and_move\n    http_get(\n    ~~~~~~~~^\n        url_to_download,\n        ^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n        expected_size=expected_size,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 511, in http_get\n    return http_get(\n        url=url,\n    ...<6 lines>...\n        _tqdm_bar=_tqdm_bar,\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 420, in http_get\n    r = _request_wrapper(\n        method=\"GET\", url=url, stream=True, proxies=proxies, headers=headers, timeout=constants.HF_HUB_DOWNLOAD_TIMEOUT\n    )\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\file_download.py\", line 309, in _request_wrapper\n    response = http_backoff(method=method, url=url, **params, retry_on_exceptions=(), retry_on_status_codes=(429,))\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 310, in http_backoff\n    response = session.request(method=method, url=url, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n    resp = self.send(prep, **send_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n    r = adapter.send(request, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py\", line 96, in send\n    return super().send(request, *args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send\n    raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: (MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /distilbert/distilbert-base-uncased-finetuned-sst-2-english/resolve/714eb0f/model.safetensors (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000001C6FD251F90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 09e99534-f013-4b02-a65d-9f1e16e03ff3)')\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 600, in from_pretrained\n    return model_class.from_pretrained(\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nwhile loading with TFAutoModelForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 737, in getattribute_from_module\n    return getattribute_from_module(transformers_module, attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 741, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 597, in from_pretrained\n    model_class = _get_model_class(config, cls._model_mapping)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 394, in _get_model_class\n    supported_models = model_mapping[type(config)]\n                       ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 803, in __getitem__\n    return self._load_attr_from_module(model_type, model_name)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 817, in _load_attr_from_module\n    return getattribute_from_module(self._modules[module_name], attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 739, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} neither in {module} nor in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification neither in <module 'transformers.models.distilbert' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\models\\\\distilbert\\\\__init__.py'> nor in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 737, in getattribute_from_module\n    return getattribute_from_module(transformers_module, attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 741, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 597, in from_pretrained\n    model_class = _get_model_class(config, cls._model_mapping)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 394, in _get_model_class\n    supported_models = model_mapping[type(config)]\n                       ~~~~~~~~~~~~~^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 803, in __getitem__\n    return self._load_attr_from_module(model_type, model_name)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 817, in _load_attr_from_module\n    return getattribute_from_module(self._modules[module_name], attr)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\", line 739, in getattribute_from_module\n    raise ValueError(f\"Could not find {attr} neither in {module} nor in {transformers_module}!\")\nValueError: Could not find TFDistilBertForSequenceClassification neither in <module 'transformers.models.distilbert' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\models\\\\distilbert\\\\__init__.py'> nor in <module 'transformers' from 'c:\\\\Users\\\\Abrarali\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python313\\\\Lib\\\\site-packages\\\\transformers\\\\__init__.py'>!\n\nwhile loading with DistilBertForSequenceClassification, an error is thrown:\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 292, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\pipelines\\base.py\", line 310, in infer_framework_load_model\n    model = model_class.from_pretrained(model, **fp32_kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 311, in _wrapper\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 4680, in from_pretrained\n    checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n                                         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        pretrained_model_name_or_path=pretrained_model_name_or_path,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<15 lines>...\n        transformers_explicit_filename=transformers_explicit_filename,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\modeling_utils.py\", line 1243, in _get_resolved_checkpoint_files\n    raise OSError(\n    ...<3 lines>...\n    )\nOSError: distilbert/distilbert-base-uncased-finetuned-sst-2-english does not appear to have a file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt or flax_model.msgpack.\n\n\n"
     ]
    }
   ],
   "source": [
    "# Ensure tf-keras is installed for compatibility with Transformers and Keras 3\n",
    "%pip install -q tf-keras\n",
    "\n",
    "# Sentiment analysis using VADER\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "text_df['vader_sentiment'] = text_df['response'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Optionally, use HuggingFace transformer model for sentiment\n",
    "if pipeline:\n",
    "    hf_sentiment = pipeline('sentiment-analysis')\n",
    "    text_df['hf_sentiment'] = text_df['response'].apply(lambda x: hf_sentiment(x)[0]['label'])\n",
    "else:\n",
    "    text_df['hf_sentiment'] = None\n",
    "\n",
    "display(text_df[['response', 'vader_sentiment', 'hf_sentiment']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91a65e9",
   "metadata": {},
   "source": [
    "## 6. Topic Modeling\n",
    "We will use LDA (Latent Dirichlet Allocation) for topic modeling, and demonstrate BERTopic if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic modeling with LDA\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(text_df['processed'])\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_topics = lda.fit_transform(dtm)\n",
    "\n",
    "# Display top words for each topic\n",
    "def print_top_words(model, feature_names, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx+1}: \",\n",
    "              \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print_top_words(lda, vectorizer.get_feature_names_out())\n",
    "\n",
    "# Optionally, BERTopic\n",
    "if BERTopic:\n",
    "    bertopic_model = BERTopic()\n",
    "    topics, probs = bertopic_model.fit_transform(text_df['processed'])\n",
    "    text_df['bertopic'] = topics\n",
    "    print('BERTopic topics:', set(topics))\n",
    "else:\n",
    "    text_df['bertopic'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bca830",
   "metadata": {},
   "source": [
    "## 7. Keyword Extraction\n",
    "We will extract keywords from the text responses using RAKE or KeyBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e332d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword extraction with RAKE or KeyBERT\n",
    "if Rake:\n",
    "    rake = Rake()\n",
    "    text_df['rake_keywords'] = text_df['response'].apply(lambda x: rake.extract_keywords_from_text(x) or rake.get_ranked_phrases())\n",
    "    print('Sample RAKE keywords:', text_df['rake_keywords'].head().tolist())\n",
    "elif KeyBERT:\n",
    "    kw_model = KeyBERT()\n",
    "    text_df['keybert_keywords'] = text_df['response'].apply(lambda x: kw_model.extract_keywords(x, top_n=5))\n",
    "    print('Sample KeyBERT keywords:', text_df['keybert_keywords'].head().tolist())\n",
    "else:\n",
    "    print('Neither RAKE nor KeyBERT is available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26ddf25",
   "metadata": {},
   "source": [
    "## 8. Visualizations\n",
    "We will visualize frequent terms (WordCloud), sentiment distribution (bar chart), and top topics with sample answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WordCloud for frequent terms\n",
    "all_words = ' '.join(text_df['processed'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('WordCloud of Frequent Terms')\n",
    "plt.show()\n",
    "\n",
    "# Bar chart for sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(text_df['vader_sentiment'], bins=20, kde=True)\n",
    "plt.title('Sentiment Distribution (VADER)')\n",
    "plt.xlabel('Compound Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Top topics with sample answers (LDA)\n",
    "lda_topic_assignments = lda_topics.argmax(axis=1)\n",
    "text_df['lda_topic'] = lda_topic_assignments\n",
    "for topic_num in range(lda.n_components):\n",
    "    print(f'\\nTopic {topic_num+1} sample answers:')\n",
    "    display(text_df[text_df['lda_topic'] == topic_num]['response'].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3098ab",
   "metadata": {},
   "source": [
    "## 9. Results and Insights\n",
    "\n",
    "- **WordCloud** highlights the most frequent terms in open-ended responses.\n",
    "- **Sentiment analysis** shows the distribution of positive, neutral, and negative feedback.\n",
    "- **Topic modeling** groups responses into main themes/topics, with sample answers for each.\n",
    "- **Keyword extraction** surfaces the most important phrases and terms.\n",
    "\n",
    "These analyses help identify key concerns, suggestions, and overall sentiment from open-ended survey feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
