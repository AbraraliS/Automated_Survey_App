{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05383fca",
   "metadata": {},
   "source": [
    "# Predictive Modeling on Survey Data\n",
    "\n",
    "This notebook builds and evaluates classification models to predict overall satisfaction ratings from survey responses, using MCQ answers and text embeddings as features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56056a3",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We will use pandas, numpy, scikit-learn, matplotlib, seaborn, and optionally XGBoost/LightGBM for modeling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13c11196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Optional imports\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "except ImportError:\n",
    "    XGBClassifier = None\n",
    "try:\n",
    "    from lightgbm import LGBMClassifier\n",
    "except ImportError:\n",
    "    LGBMClassifier = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9f14d",
   "metadata": {},
   "source": [
    "## 2. Load Survey Responses from JSON\n",
    "We will load the survey responses from the JSON file (`survey-results.json`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329ec4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'dict'>\n",
      "survey: {'survey_id': 'f5ae24e1-9985-450b-b36c-878ffa7f471d', 'topic': 'Student AI/ML session review', 'audience': 'College Student', 'created_at': '2025-08-30T16:56:55.019098+00:00', 'questions_count': 5, 'responses_count': 5} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the survey data from JSON file\n",
    "with open('survey-results-f5ae24e1-9985-450b-b36c-878ffa7f471d.json', 'r', encoding='utf-8') as f:\n",
    "    survey_data = json.load(f)\n",
    "\n",
    "# Preview the structure of the JSON data\n",
    "print('Type:', type(survey_data))\n",
    "if isinstance(survey_data, dict):\n",
    "    for k, v in survey_data.items():\n",
    "        print(f'{k}:', str(v)[:300], '\\n')\n",
    "        break\n",
    "elif isinstance(survey_data, list):\n",
    "    print('Sample record:', survey_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c044064",
   "metadata": {},
   "source": [
    "## 3. Build Dataset: Target and Features\n",
    "We will extract the target variable (overall rating) and use other MCQ answers and text embeddings as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9662731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['response_id', 'survey_id', 'user_id', 'user_name', 'user_email', 'responses', 'submitted_at', 'completion_time', 'user_ip']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>survey_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_email</th>\n",
       "      <th>responses</th>\n",
       "      <th>submitted_at</th>\n",
       "      <th>completion_time</th>\n",
       "      <th>user_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4a9fb051-773a-42f5-aba0-8f9aed440cef</td>\n",
       "      <td>f5ae24e1-9985-450b-b36c-878ffa7f471d</td>\n",
       "      <td>4a9fb051-773a-42f5-aba0-8f9aed440cef</td>\n",
       "      <td>Vinod</td>\n",
       "      <td>null@gmail.com</td>\n",
       "      <td>{'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Exce...</td>\n",
       "      <td>2025-09-02T16:22:28.297071+00:00</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51d4b21f-cb53-4592-8f2b-4228d6d2d668</td>\n",
       "      <td>f5ae24e1-9985-450b-b36c-878ffa7f471d</td>\n",
       "      <td>51d4b21f-cb53-4592-8f2b-4228d6d2d668</td>\n",
       "      <td>Vicky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Exce...</td>\n",
       "      <td>2025-09-01T09:06:02.399015+00:00</td>\n",
       "      <td>265</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90a0bddd-820d-47f6-9239-6333808ab425</td>\n",
       "      <td>f5ae24e1-9985-450b-b36c-878ffa7f471d</td>\n",
       "      <td>90a0bddd-820d-47f6-9239-6333808ab425</td>\n",
       "      <td>Nutan</td>\n",
       "      <td>nutan@gmail.com</td>\n",
       "      <td>{'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Good...</td>\n",
       "      <td>2025-08-30T17:14:57.538162+00:00</td>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>657bfbf0-f8e4-43a6-aab7-97ff455c82ba</td>\n",
       "      <td>f5ae24e1-9985-450b-b36c-878ffa7f471d</td>\n",
       "      <td>657bfbf0-f8e4-43a6-aab7-97ff455c82ba</td>\n",
       "      <td>Vicky</td>\n",
       "      <td>vi@gmail.com</td>\n",
       "      <td>{'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Fair...</td>\n",
       "      <td>2025-08-30T17:11:53.569637+00:00</td>\n",
       "      <td>227</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d05de1e4-86cb-4aca-a685-027f983ae041</td>\n",
       "      <td>f5ae24e1-9985-450b-b36c-878ffa7f471d</td>\n",
       "      <td>d05de1e4-86cb-4aca-a685-027f983ae041</td>\n",
       "      <td>Aman</td>\n",
       "      <td>aman@gmail.com</td>\n",
       "      <td>{'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Good...</td>\n",
       "      <td>2025-08-30T16:58:42.383539+00:00</td>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            response_id                             survey_id  \\\n",
       "0  4a9fb051-773a-42f5-aba0-8f9aed440cef  f5ae24e1-9985-450b-b36c-878ffa7f471d   \n",
       "1  51d4b21f-cb53-4592-8f2b-4228d6d2d668  f5ae24e1-9985-450b-b36c-878ffa7f471d   \n",
       "2  90a0bddd-820d-47f6-9239-6333808ab425  f5ae24e1-9985-450b-b36c-878ffa7f471d   \n",
       "3  657bfbf0-f8e4-43a6-aab7-97ff455c82ba  f5ae24e1-9985-450b-b36c-878ffa7f471d   \n",
       "4  d05de1e4-86cb-4aca-a685-027f983ae041  f5ae24e1-9985-450b-b36c-878ffa7f471d   \n",
       "\n",
       "                                user_id user_name       user_email  \\\n",
       "0  4a9fb051-773a-42f5-aba0-8f9aed440cef     Vinod   null@gmail.com   \n",
       "1  51d4b21f-cb53-4592-8f2b-4228d6d2d668     Vicky              NaN   \n",
       "2  90a0bddd-820d-47f6-9239-6333808ab425     Nutan  nutan@gmail.com   \n",
       "3  657bfbf0-f8e4-43a6-aab7-97ff455c82ba     Vicky     vi@gmail.com   \n",
       "4  d05de1e4-86cb-4aca-a685-027f983ae041      Aman   aman@gmail.com   \n",
       "\n",
       "                                           responses  \\\n",
       "0  {'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Exce...   \n",
       "1  {'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Exce...   \n",
       "2  {'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Good...   \n",
       "3  {'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Fair...   \n",
       "4  {'252bb7b5-f70c-4a85-a2ab-2ae6b35bb524': 'Good...   \n",
       "\n",
       "                       submitted_at  completion_time  user_ip  \n",
       "0  2025-09-02T16:22:28.297071+00:00              315      NaN  \n",
       "1  2025-09-01T09:06:02.399015+00:00              265  unknown  \n",
       "2  2025-08-30T17:14:57.538162+00:00              262      NaN  \n",
       "3  2025-08-30T17:11:53.569637+00:00              227      NaN  \n",
       "4  2025-08-30T16:58:42.383539+00:00              158      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please update the code with the correct target column name.\n",
      "Target column: None\n",
      "Text column: None\n"
     ]
    }
   ],
   "source": [
    "# Extract records and build DataFrame\n",
    "def extract_records(survey_data):\n",
    "    if isinstance(survey_data, dict):\n",
    "        for key in ['responses', 'data', 'results', 'answers']:\n",
    "            if key in survey_data:\n",
    "                records = survey_data[key]\n",
    "                break\n",
    "        else:\n",
    "            records = list(survey_data.values())\n",
    "    elif isinstance(survey_data, list):\n",
    "        records = survey_data\n",
    "    else:\n",
    "        records = []\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "df = extract_records(survey_data)\n",
    "print('Columns:', df.columns.tolist())\n",
    "display(df.head())\n",
    "\n",
    "# Identify target and feature columns\n",
    "target_col = None\n",
    "for col in df.columns:\n",
    "    if 'overall' in col.lower() and 'rating' in col.lower():\n",
    "        target_col = col\n",
    "        break\n",
    "if not target_col:\n",
    "    print('Please update the code with the correct target column name.')\n",
    "\n",
    "# Example: text_col = 'open_feedback' (update as needed)\n",
    "text_col = None\n",
    "for col in df.columns:\n",
    "    if 'text' in col.lower() or 'feedback' in col.lower() or 'comment' in col.lower():\n",
    "        text_col = col\n",
    "        break\n",
    "print('Target column:', target_col)\n",
    "print('Text column:', text_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defb870b",
   "metadata": {},
   "source": [
    "## 4. Encode Categorical Features\n",
    "We will encode categorical MCQ features using LabelEncoder or OneHotEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e185c333",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:460\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7293\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7203\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'dict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m y = le.fit_transform(df[target_col].astype(\u001b[38;5;28mstr\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m target_col \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# One-hot encode features\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m X_cat = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m feature_cols \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCategorical feature shape:\u001b[39m\u001b[33m'\u001b[39m, X_cat.shape)\n\u001b[32m     11\u001b[39m display(X_cat.head())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:215\u001b[39m, in \u001b[36mget_dummies\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    211\u001b[39m     with_dummies = [data.select_dtypes(exclude=dtypes_to_encode)]\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, pre, sep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(data_to_encode.items(), prefix, prefix_sep):\n\u001b[32m    214\u001b[39m     \u001b[38;5;66;03m# col is (column_name, column), use just column data here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m     dummy = \u001b[43m_get_dummies_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix_sep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdummy_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    224\u001b[39m     with_dummies.append(dummy)\n\u001b[32m    225\u001b[39m result = concat(with_dummies, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:251\u001b[39m, in \u001b[36m_get_dummies_1d\u001b[39m\u001b[34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconcat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m concat\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# Series avoids inconsistent NaN handling\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m codes, levels = \u001b[43mfactorize_from_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    254\u001b[39m     input_dtype = data.dtype\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:3075\u001b[39m, in \u001b[36mfactorize_from_iterable\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m   3070\u001b[39m     codes = values.codes\n\u001b[32m   3071\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3072\u001b[39m     \u001b[38;5;66;03m# The value of ordered is irrelevant since we don't use cat as such,\u001b[39;00m\n\u001b[32m   3073\u001b[39m     \u001b[38;5;66;03m# but only the resulting categories, the order of which is independent\u001b[39;00m\n\u001b[32m   3074\u001b[39m     \u001b[38;5;66;03m# from ordered. Set ordered to False as default. See GH #15457\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3075\u001b[39m     cat = \u001b[43mCategorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mordered\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3076\u001b[39m     categories = cat.categories\n\u001b[32m   3077\u001b[39m     codes = cat.codes\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arrays\\categorical.py:462\u001b[39m, in \u001b[36mCategorical.__init__\u001b[39m\u001b[34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[39m\n\u001b[32m    460\u001b[39m     codes, categories = factorize(values, sort=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     codes, categories = \u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype.ordered:\n\u001b[32m    464\u001b[39m         \u001b[38;5;66;03m# raise, as we don't have a sortable data structure and so\u001b[39;00m\n\u001b[32m    465\u001b[39m         \u001b[38;5;66;03m# the user should give us one by specifying categories\u001b[39;00m\n\u001b[32m    466\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    467\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is not ordered, please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    468\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mexplicitly specify the categories order \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    469\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mby passing in a categories argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    470\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:795\u001b[39m, in \u001b[36mfactorize\u001b[39m\u001b[34m(values, sort, use_na_sentinel, size_hint)\u001b[39m\n\u001b[32m    792\u001b[39m             \u001b[38;5;66;03m# Don't modify (potentially user-provided) array\u001b[39;00m\n\u001b[32m    793\u001b[39m             values = np.where(null_mask, na_value, values)\n\u001b[32m--> \u001b[39m\u001b[32m795\u001b[39m     codes, uniques = \u001b[43mfactorize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m0\u001b[39m:\n\u001b[32m    802\u001b[39m     uniques, codes = safe_sort(\n\u001b[32m    803\u001b[39m         uniques,\n\u001b[32m    804\u001b[39m         codes,\n\u001b[32m   (...)\u001b[39m\u001b[32m    807\u001b[39m         verify=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    808\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abrarali\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:595\u001b[39m, in \u001b[36mfactorize_array\u001b[39m\u001b[34m(values, use_na_sentinel, size_hint, na_value, mask)\u001b[39m\n\u001b[32m    592\u001b[39m hash_klass, values = _get_hashtable_algo(values)\n\u001b[32m    594\u001b[39m table = hash_klass(size_hint \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(values))\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m uniques, codes = \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_sentinel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_na_sentinel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;66;03m# re-cast e.g. i8->dt64/td64, uint8->bool\u001b[39;00m\n\u001b[32m    604\u001b[39m uniques = _reconstruct_data(uniques, original.dtype, original)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7293\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7203\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "feature_cols = [col for col in df.columns if col != target_col and col != text_col and df[col].dtype == 'object']\n",
    "\n",
    "# Label encode target\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[target_col].astype(str)) if target_col else None\n",
    "\n",
    "# One-hot encode features\n",
    "X_cat = pd.get_dummies(df[feature_cols], dummy_na=True) if feature_cols else pd.DataFrame()\n",
    "print('Categorical feature shape:', X_cat.shape)\n",
    "display(X_cat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92009817",
   "metadata": {},
   "source": [
    "## 5. Convert Text Answers into Features\n",
    "We will use TF-IDF vectorization or sentence embeddings for text answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ccd80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text answers into features using TF-IDF\n",
    "if text_col:\n",
    "    tfidf = TfidfVectorizer(max_features=100)\n",
    "    X_text = tfidf.fit_transform(df[text_col].fillna('')).toarray()\n",
    "    print('TF-IDF feature shape:', X_text.shape)\n",
    "else:\n",
    "    X_text = np.empty((len(df), 0))\n",
    "\n",
    "# Combine all features\n",
    "from numpy import hstack\n",
    "X = hstack([X_cat.values, X_text]) if X_cat.shape[1] > 0 or X_text.shape[1] > 0 else None\n",
    "print('Final feature matrix shape:', X.shape if X is not None else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a37430",
   "metadata": {},
   "source": [
    "## 6. Train Classification Models\n",
    "We will train Logistic Regression, Random Forest, and Gradient Boosting models to predict satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926dfd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "if X is not None and y is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "else:\n",
    "    print('Missing features or target.')\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "results['Logistic Regression'] = y_pred_lr\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "results['Random Forest'] = y_pred_rf\n",
    "\n",
    "# Gradient Boosting (XGBoost or LightGBM if available)\n",
    "if XGBClassifier:\n",
    "    xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb.predict(X_test)\n",
    "    results['XGBoost'] = y_pred_xgb\n",
    "elif LGBMClassifier:\n",
    "    lgbm = LGBMClassifier()\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    y_pred_lgbm = lgbm.predict(X_test)\n",
    "    results['LightGBM'] = y_pred_lgbm\n",
    "else:\n",
    "    gbc = GradientBoostingClassifier()\n",
    "    gbc.fit(X_train, y_train)\n",
    "    y_pred_gbc = gbc.predict(X_test)\n",
    "    results['Gradient Boosting'] = y_pred_gbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12e45d",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "We will evaluate each model using accuracy, F1-score, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8f22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models\n",
    "for model_name, y_pred in results.items():\n",
    "    print(f'\\nModel: {model_name}')\n",
    "    print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('F1-score:', f1_score(y_test, y_pred, average='weighted'))\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccceaa",
   "metadata": {},
   "source": [
    "## 8. Feature Importance\n",
    "We will show feature importance for tree-based models to understand which factors best predict satisfaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature importance for tree-based models\n",
    "feature_names = list(X_cat.columns) + (tfidf.get_feature_names_out().tolist() if text_col else [])\n",
    "\n",
    "for model, name in zip([rf, gbc if 'gbc' in locals() else None], ['Random Forest', 'Gradient Boosting']):\n",
    "    if model is not None:\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[-10:][::-1]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.title(f'Top 10 Feature Importances: {name}')\n",
    "        plt.barh(range(len(indices)), importances[indices], align='center')\n",
    "        plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "        plt.xlabel('Importance')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69272f19",
   "metadata": {},
   "source": [
    "## 9. Interpretation and Insights\n",
    "\n",
    "- The most important features (from tree-based models) indicate which MCQ answers and text-derived features best predict overall satisfaction.\n",
    "- Review the top features and their values to understand what drives high or low ratings.\n",
    "- Use these insights to improve future surveys or interventions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
